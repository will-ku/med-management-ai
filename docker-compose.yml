services:
  frontend:
    build: ./frontend
    ports:
      - "5173:5173"
    volumes:
      - ./frontend:/app
      - frontend_node_modules:/app/node_modules
    environment:
      - VITE_API_URL=http://localhost:3000
    depends_on:
      - backend

  backend:
    build:
      context: ./backend
      dockerfile: Dockerfile
    ports:
      - "3000:3000"
    volumes:
      - ./backend:/app
      - backend_node_modules:/app/node_modules
      - ./backend/data:/app/data
    environment:
      - NODE_ENV=development
      - PORT=3000
      - OLLAMA_API_URL=http://ollama:11434
    depends_on:
      - ollama

  ollama:
    image: ollama/ollama:latest
    ports:
      - "11434:11434"
    volumes:
      - ollama_data:/root/.ollama
      - ./start-ollama.sh:/start-ollama.sh
    healthcheck:
      test: curl -f http://localhost:11434/api/version || exit 1
      interval: 10s
      timeout: 5s
      retries: 3
    entrypoint: ["/bin/sh"]
    command: ["/start-ollama.sh"]

volumes:
  frontend_node_modules:
  backend_node_modules:
  ollama_data:
# services:
#   frontend:
#     build: ./frontend
#     ports:
#       - "5173:5173"
#     volumes:
#       - ./frontend:/app
#       - node_modules:/app/node_modules
#     environment:
#       - VITE_API_URL=http://localhost:3000
#     depends_on:
#       - backend

#   backend:
#     build:
#       context: ./backend
#       dockerfile: Dockerfile
#     ports:
#       - "3000:3000"
#     volumes:
#       - ./backend:/app
#       # - /app/node_modules
#       - ./backend/data:/app/data
#     environment:
#       - NODE_ENV=development
#       - PORT=3000
#       - OLLAMA_API_URL=http://ollama:11434
#     depends_on:
#       - ollama

#   ollama:
#     image: ollama/ollama:latest
#     ports:
#       - "11434:11434"
#     volumes:
#       - ollama_data:/root/.ollama
#       - ./start-ollama.sh:/start-ollama.sh
#     healthcheck:
#       test: curl -f http://localhost:11434/api/version || exit 1
#       interval: 10s
#       timeout: 5s
#       retries: 3
#     entrypoint: ["/bin/sh"]
#     command: ["/start-ollama.sh"]

# volumes:
#   ollama_data:
#   node_modules:
